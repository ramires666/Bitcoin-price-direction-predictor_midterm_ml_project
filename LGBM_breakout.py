# Fix Windows CPU core detection warning before any imports
import os
import warnings
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend to avoid display issues

# Set LOKY_MAX_CPU_COUNT to fix Windows CPU detection warning
os.environ["LOKY_MAX_CPU_COUNT"] = "0"  # 0 means use all available cores
# Suppress the specific warning about physical core detection
warnings.filterwarnings("ignore", message=".*Could not find the number of physical cores.*")
warnings.filterwarnings("ignore", message=".*Returning the number of logical cores instead.*")
# Suppress LightGBM feature names warning
warnings.filterwarnings("ignore", message=".*X does not have valid feature names.*")
warnings.filterwarnings("ignore", message=".*LGBMClassifier was fitted with feature names.*")
# Suppress matplotlib font warnings
warnings.filterwarnings("ignore", message=".*missing from font.*")
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")

# %% [markdown]
# # –ú–æ–¥–µ–ª—å LightGBM –¥–ª—è –ø–æ–∏—Å–∫–∞ "–ø—Ä–æ–±–æ–µ–≤" (Breakouts)
#
# ### –¶–µ–ª–∏ —ç—Ç–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞:
# 1. **–î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏**: –í–≤–µ—Å—Ç–∏ –®–∏—Ä–∏–Ω—É –ü–æ–ª–æ—Å –ë–æ–ª–ª–∏–Ω–¥–∂–µ—Ä–∞ (`BBW`) –∫–∞–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä "–∑–∞—Ç–∏—à—å—è" –ø–µ—Ä–µ–¥ "–±—É—Ä–µ–π".
# 2. **–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≥–∏–ø–æ—Ç–µ–∑—É "—Ç–æ—Ä–≥–æ–≤–ª–∏ –ø—Ä–æ–±–æ–µ–≤"**: –°–º–æ–∂–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å, –≤–∏–¥—è —Å—É–∂–µ–Ω–∏–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ + –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª, –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å–∏–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ.
# 3. **–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ –ª—É—á—à–∏–µ –Ω–∞—Ä–∞–±–æ—Ç–∫–∏**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—ä–µ–º–Ω—ã–µ —Ñ–∏—á–∏, "—É–º–Ω—ã–µ" —Å–∏–≥–Ω–∞–ª—ã –∏ –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –≤–º–µ—Å—Ç–µ.
# 4. **–°–æ–∑–¥–∞—Ç—å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é**: –û–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (—Ñ–æ–Ω–æ–≤—ã–µ –ø–æ–ª–æ—Å—ã) –∏ —Ä–µ–∞–ª—å–Ω—ã–µ –∏—Å—Ö–æ–¥—ã (—Ü–≤–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∞).
# 5. **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—ä–µ–º–Ω—ã–µ —Ñ–∏—á–∏**: –í–µ—Ä–Ω—É—Ç—å –≤—Å–µ –∫—É–º—É–ª—è—Ç–∏–≤–Ω—ã–µ –¥–µ–ª—å—Ç—ã –æ–±—ä–µ–º–æ–≤.
# 6. **–Ø–≤–Ω–æ —É–¥–∞–ª–∏—Ç—å NaN**: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Å NaN —É–¥–∞–ª–µ–Ω—ã –ø–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.

# %%
# =============================================
# –Ø—á–µ–π–∫–∞ 1: –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏ –±–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
# =============================================
import pandas as pd
import numpy as np
import pandas_ta as ta
import matplotlib.pyplot as plt
import seaborn as sns
from lightgbm import LGBMClassifier, early_stopping
from itertools import product
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    log_loss # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º log_loss –Ω–∞–ø—Ä—è–º—É—é
)
from scipy.fft import fft, ifft # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –§—É—Ä—å–µ-–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
from typing import Optional # –î–ª—è Optional –≤ plot_advanced_signals

# Import our advanced backtester
from advanced_backtester import advanced_backtester

# –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
RANDOM_STATE = 42
# –§–ª–∞–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –≤ LightGBM (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ç–∫–ª—é—á—ë–Ω)
USE_GPU = False

# üî• –ü–û–î–û–ë–†–ê–ù–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ FFT –ò–ó fft_simple_analysis.py ‚úÖ
FFT_MIN_CUTOFF = 20
FFT_CUTOFF_FRACTION = 80
NEUTRAL_SLOPE_THRESHOLD = 30.0  # |slope| < 30 USDT/15m ‚Üí –Ω–µ–π—Ç—Ä–∞–ª (—Å–µ—Ä—ã–π)
COMMISSION = 0.0000275  # –ö–æ–º–∏—Å—Å–∏—è 0.0275%

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è Pandas
pd.set_option("display.max_rows", 100)
pd.set_option("display.max_columns", 100)
pd.set_option("display.width", 120)

# %% [markdown]
# ## –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
#
# –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —à–∞–≥ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.

# %%
# =============================================
# –Ø—á–µ–π–∫–∞ 2: –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
# =============================================
def load_and_merge_data(
    fundings_path: str = "data/processed/fundings.parquet",
    klines_path: str = "data/processed/klines_15min_all.parquet",
    volumes_path: str = "data/processed/aggtrades_15min_all.parquet",
) -> pd.DataFrame:
    fundings = pd.read_parquet(fundings_path)
    klines = pd.read_parquet(klines_path)
    volumes = pd.read_parquet(volumes_path)

    if "datetime" in volumes.columns: volumes = volumes.rename(columns={"datetime": "time"})
    if "calc_time" in fundings.columns: fundings = fundings.rename(columns={"calc_time": "time"})
    if "open_time" in klines.columns: klines = klines.rename(columns={"open_time": "time"})

    for col in ["time"]:
        volumes[col] = pd.to_datetime(volumes[col], utc=True)
        fundings[col] = pd.to_datetime(fundings[col], utc=True)
        klines[col] = pd.to_datetime(klines[col], utc=True)

    df = pd.merge(volumes, klines, on="time", how="inner")
    df = pd.merge(df, fundings, on="time", how="left")

    df = df.sort_values("time").reset_index(drop=True)
    if "funding_rate" in df.columns:
        df["funding_rate"] = df["funding_rate"].ffill()

    return df

# %% [markdown]
# ## –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏ –æ–±—ä–µ–º)
#
# –†–∞—Å—à–∏—Ä—è–µ–º `add_volume_features` –∏ –¥–æ–±–∞–≤–ª—è–µ–º `add_volatility_features`.

# %%
# =============================================
# –Ø—á–µ–π–∫–∞ 3: –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
# =============================================

def add_volume_features(df: pd.DataFrame) -> pd.DataFrame:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–º–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞."""
    df["volume_delta"] = df["ask_vol"] - df["bid_vol"]
    df["volume_delta_max"] = df["max_ask_vol"] - df["max_bid_vol"]
    df["volume_delta_avg"] = df["avg_ask_vol"] - df["avg_bid_vol"]
    
    base_windows = [4, 8, 16, 32, 96] # 1, 2, 4, 8, 24 —á–∞—Å–æ–≤ –¥–ª—è 15–º
    for window in base_windows:
        df[f"cumulative_volume_delta_{window}"] = df["volume_delta"].rolling(window=window, min_periods=1).sum()
        df[f"cumulative_ask_bid_diff_{window}"] = (
            df["ask_vol"].rolling(window=window, min_periods=1).sum() - 
            df["bid_vol"].rolling(window=window, min_periods=1).sum()
        )
    return df

def add_strategy_features(df: pd.DataFrame) -> pd.DataFrame:
    df.ta.ema(length=12, append=True, col_names="EMA_12")
    df.ta.ema(length=26, append=True, col_names="EMA_26")
    
    # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π MACD —Å —è–≤–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ –∫–æ–ª–æ–Ω–æ–∫
    df.ta.macd(fast=12, slow=26, signal=9, append=True, col_names=("MACD_12_26_9", "MACDH_12_26_9", "MACDS_12_26_9"))
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ MACD —Å —è–≤–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ –∫–æ–ª–æ–Ω–æ–∫
    df.ta.macd(fast=7, slow=14, signal=7, append=True, col_names=("MACD_7_14_7", "MACDH_7_14_7", "MACDS_7_14_7"))
    df.ta.macd(fast=24, slow=52, signal=18, append=True, col_names=("MACD_24_52_18", "MACDH_24_52_18", "MACDS_24_52_18"))

    df.ta.rsi(length=14, append=True, col_names="RSI_14")

    df['ema_trend'] = np.sign(df['EMA_12'] - df['EMA_26'])
    df['macd_crossover'] = np.sign(df['MACD_12_26_9'] - df['MACDS_12_26_9']).diff()
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã MACD
    df['macd_crossover_7_14_7'] = np.sign(df['MACD_7_14_7'] - df['MACDS_7_14_7']).diff()
    df['macd_crossover_24_52_18'] = np.sign(df['MACD_24_52_18'] - df['MACDS_24_52_18']).diff()
    
    return df

def add_volatility_features(df: pd.DataFrame) -> pd.DataFrame:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏. –ù–∞–¥–µ–∂–Ω—ã–π –º–µ—Ç–æ–¥."""
    
    # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ Bollinger Bands —Å —è–≤–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ –∫–æ–ª–æ–Ω–æ–∫ (std=2.0 -> 2)
    df.ta.bbands(length=20, std=2, append=True, col_names=(f"BBL_20_2", f"BBM_20_2", f"BBU_20_2", f"BBB_20_2", f"BBP_20_2"))
    
    # –†–∞—Å—á–µ—Ç BBW –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö BB
    df['bbw'] = (df[f"BBU_20_2"] - df[f"BBL_20_2"]) / df[f"BBM_20_2"]
    df['bbw_sma_10'] = df['bbw'].rolling(10).mean()

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ Bollinger Bands
    bb_params = [(10, 1.5), (30, 2.5)]
    for length, std in bb_params:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–æ–∫–æ–≤–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è std, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º float –≤ –∏–º–µ–Ω–∞—Ö –∫–æ–ª–æ–Ω–æ–∫
        # –ù–∞–ø—Ä–∏–º–µ—Ä, 1.5 -> 1_5
        std_str = str(std).replace('.', '_') 
        df.ta.bbands(length=length, std=std, append=True, col_names=(f"BBL_{length}_{std_str}", f"BBM_{length}_{std_str}", f"BBU_{length}_{std_str}", f"BBB_{length}_{std_str}", f"BBP_{length}_{std_str}"))
        
        df[f'bbw_{length}_{std_str}'] = (df[f"BBU_{length}_{std_str}"] - df[f"BBL_{length}_{std_str}"]) / df[f"BBM_{length}_{std_str}"]
        df[f'bbw_sma_10_{length}_{std_str}'] = df[f'bbw_{length}_{std_str}'].rolling(10).mean()
    
    return df

# %% [markdown]
# ## –®–∞–≥ 3: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ 3-–∫–ª–∞—Å—Å–æ–≤–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
#
# –ò—Å–ø–æ–ª—å–∑—É–µ–º "–º–µ—Ä—Ç–≤—É—é –∑–æ–Ω—É" (threshold) –¥–ª—è –æ—Ç—Å–µ—á–µ–Ω–∏—è —Ä—ã–Ω–æ—á–Ω–æ–≥–æ —à—É–º–∞.

# %%
# =============================================
# –Ø—á–µ–π–∫–∞ 4: –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è 3-–∫–ª–∞—Å—Å–æ–≤–æ–π —Ü–µ–ª–∏
# =============================================

def prepare_fft_target(
    df: pd.DataFrame,
    threshold: float = 0.0005,
    cutoff_ratio: float = 0.1
) -> tuple:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ FFT-–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π.
    
    Args:
        df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–æ–π 'close'
        threshold: –ø–æ—Ä–æ–≥ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–≤–µ—Ä—Ö/–Ω–∏–∑/–Ω–µ–π—Ç—Ä–∞–ª)
        cutoff_ratio: –¥–æ–ª—è —Å–æ—Ö—Ä–∞–Ω—è–µ–º—ã—Ö —á–∞—Å—Ç–æ—Ç –≤ FFT (0.0-1.0)
        
    Returns:
        tuple: (fft_signal, fft_signal_diff)
    """
    close_prices = df['close'].values
    N = len(close_prices)
    
    if N == 0:
        print("No data for FFT target generation.")
        return np.full(N, np.nan), np.full(N, np.nan)

    # –£–±–∏—Ä–∞–µ–º —Ç—Ä–µ–Ω–¥ –¥–ª—è –ª—É—á—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ FFT
    mean_price = np.mean(close_prices)
    detrended_prices = close_prices - mean_price
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º FFT –∫ –¥–µ—Ç—Ä–µ–Ω–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–µ—Ä–∏–∏
    yf = fft(detrended_prices)
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω—ã—Ö —à—É–º–æ–≤
    yf_filtered = np.zeros_like(yf, dtype=complex)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—É —á–∞—Å—Ç–æ—Ç –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    cutoff_freq = int(N * cutoff_ratio)
    
    # –û—Å—Ç–∞–≤–ª—è–µ–º –Ω–∏–∑–∫–æ—á–∞—Å—Ç–æ—Ç–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–≤–∫–ª—é—á–∞—è DC)
    yf_filtered[:cutoff_freq] = yf[:cutoff_freq]
    if N % 2 == 0:  # –ï—Å–ª–∏ N —á–µ—Ç–Ω–æ–µ
        yf_filtered[N-cutoff_freq:] = yf[N-cutoff_freq:]
    else:  # –ï—Å–ª–∏ N –Ω–µ—á–µ—Ç–Ω–æ–µ
        yf_filtered[N-cutoff_freq+1:] = yf[N-cutoff_freq+1:]
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ–µ FFT –¥–ª—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞
    fft_reconstructed_detrended = ifft(yf_filtered).real
    
    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç—Ä–µ–Ω–¥
    fft_reconstructed_signal = fft_reconstructed_detrended + mean_price
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É FFT —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–∏
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–≥-–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    fft_log_returns = np.diff(np.log(fft_reconstructed_signal[fft_reconstructed_signal > 0]))
    
    # –†–∞—Å—à–∏—Ä—è–µ–º fft_signal_diff –¥–æ –¥–ª–∏–Ω—ã N, –∑–∞–ø–æ–ª–Ω—è—è –ø–µ—Ä–≤—É—é –ø–æ–∑–∏—Ü–∏—é –Ω—É–ª–µ–º
    fft_signal_diff = np.concatenate([[0], fft_log_returns])
    
    return fft_reconstructed_signal, fft_signal_diff


def add_target(df: pd.DataFrame, threshold: float = 0.0005, cutoff_ratio: float = 0.1) -> pd.DataFrame:
    """–°–æ–∑–¥–∞–µ—Ç 3-–∫–ª–∞—Å—Å–æ–≤—É—é —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –Ω–∞ –æ—Å–Ω–æ–≤–µ FFT —Å–∏–≥–Ω–∞–ª–∞."""
    df_copy = df.copy()
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º FFT —Å–∏–≥–Ω–∞–ª
    fft_signal, fft_signal_diff = prepare_fft_target(
        df=df_copy,
        threshold=threshold,
        cutoff_ratio=cutoff_ratio
    )
    
    df_copy['fft_signal'] = fft_signal
    df_copy['fft_signal_diff'] = fft_signal_diff
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ fft_signal_diff —Å —É—á–µ—Ç–æ–º –∫–æ–º–∏—Å—Å–∏–∏
    min_signal = 7 * COMMISSION
    effective_threshold = max(threshold, min_signal)
    
    conditions = [df_copy['fft_signal_diff'] > effective_threshold, df_copy['fft_signal_diff'] < -effective_threshold]
    choices = [2, 0] # 2 –¥–ª—è UP, 0 –¥–ª—è DOWN
    df_copy['y'] = np.select(conditions, choices, default=1) # 1 –¥–ª—è SIDEWAYS
    
    # –í—ã–≤–æ–¥–∏–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ FFT
    print(f"FFT Debug Info:")
    print(f"- Cutoff ratio: {cutoff_ratio} (preserving {cutoff_ratio*100}% of frequencies)")
    print(f"- FFT signal stats: mean={np.mean(fft_signal):.6f}, std={np.std(fft_signal):.6f}")
    print(f"- FFT diff stats: mean={np.mean(fft_signal_diff):.6f}, std={np.std(fft_signal_diff):.6f}")
    print(f"- Threshold for classification: ¬±{effective_threshold:.6f} (base: {threshold}, min: {min_signal:.6f})")
    
    return df_copy

# %% [markdown]
# ## –®–∞–≥ 4: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
#
# –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –Ω–∞—à–∏ –ª—É—á—à–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –æ–¥–∏–Ω –Ω–∞–±–æ—Ä.

# %%
# =================================================================
# –Ø—á–µ–π–∫–∞ 5: –§—É–Ω–∫—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
# =================================================================
def prepare_features_and_split(
    df: pd.DataFrame,
    target_col: str = "y",
    train_ratio: float = 0.7,
    valid_ratio: float = 0.15
):
    df = df.copy()

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–º–µ—Å—Ç–µ
    volume_features = [col for col in df.columns if 'volume_delta' in col or 'cumulative_ask_bid_diff' in col]
    
    strategy_features = [
        'ema_trend', 'macd_crossover',
        'MACD_12_26_9', 'MACDH_12_26_9', 'MACDS_12_26_9', # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π MACD
        'MACD_7_14_7', 'MACDH_7_14_7', 'MACDS_7_14_7', 'macd_crossover_7_14_7', # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π MACD 1
        'MACD_24_52_18', 'MACDH_24_52_18', 'MACDS_24_52_18', 'macd_crossover_24_52_18', # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π MACD 2
        'RSI_14', # RSI
        # REMOVED FFT FEATURES TO PREVENT DATA LEAKAGE - FFT only used for target creation
    ]
    
    volatility_features = [
        'bbw', 'bbw_sma_10', # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π BBW
        'BBL_20_2', 'BBM_20_2', 'BBU_20_2', 'BBB_20_2', 'BBP_20_2', # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ BB (std=2.0 -> 2)
        'bbw_10_1_5', 'bbw_sma_10_10_1_5', # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π BBW 1 (std=1.5 -> 1_5)
        'BBL_10_1_5', 'BBM_10_1_5', 'BBU_10_1_5', 'BBB_10_1_5', 'BBP_10_1_5', # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ BB 1
        'bbw_30_2_5', 'bbw_sma_10_30_2_5', # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π BBW 2 (std=2.5 -> 2_5)
        'BBL_30_2_5', 'BBM_30_2_5', 'BBU_30_2_5', 'BBB_30_2_5', 'BBP_30_2_5' # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ BB 2
    ]
    
    feature_columns = list(set(volume_features + strategy_features + volatility_features))
    
    # –°–¥–≤–∏–≥–∞–µ–º –≤—Å–µ —Ñ–∏—á–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∑–∞–≥–ª—è–¥—ã–≤–∞–Ω–∏—è –≤ –±—É–¥—É—â–µ–µ
    df[feature_columns] = df[feature_columns].shift(1)

    cols_to_keep = feature_columns + [target_col, 'open', 'close', 'high', 'low']
    df = df.set_index('time')[cols_to_keep]
    
    df = df.dropna() # –Ø–≤–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ NaN –ø–æ—Å–ª–µ —Å–¥–≤–∏–≥–∞

    print(f"üîç –í–ê–ñ–ù–û: FFT –ø—Ä–∏–∑–Ω–∞–∫–∏ –ù–ï –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π)")
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(feature_columns)} —à—Ç): {feature_columns}")
    print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ:")
    print(f"{df[target_col].value_counts}(normalize=True)")
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ FFT –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –ø–æ–ø–∞–ª–∏ –≤ –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    fft_features_in_training = [col for col in feature_columns if 'fft' in col.lower()]
    if fft_features_in_training:
        print(f"‚ö†Ô∏è –û–®–ò–ë–ö–ê: FFT –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞–π–¥–µ–Ω—ã –≤ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {fft_features_in_training}")
    else:
        print(f"‚úÖ FFT –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∏—Å–∫–ª—é—á–µ–Ω—ã –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
        
    print()

    X = df[feature_columns]
    y = df[target_col]

    train_split_index = int(len(df) * train_ratio)
    valid_split_index = int(len(df) * (train_ratio + valid_ratio))

    X_train, y_train = X.iloc[:train_split_index], y.iloc[:train_split_index]
    X_valid, y_valid = X.iloc[train_split_index:valid_split_index], y.iloc[train_split_index:valid_split_index]
    X_test, y_test = X.iloc[valid_split_index:], y.iloc[valid_split_index:]

    scaler = RobustScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_valid_scaled = scaler.transform(X_valid)
    X_test_scaled = scaler.transform(X_test)
    
    test_indices = X_test.index

    return (
        X_train_scaled, y_train,
        X_valid_scaled, y_valid,
        X_test_scaled, y_test,
        scaler, feature_columns, test_indices, df
    )

# %% [markdown]
# ## –®–∞–≥ 5: –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
#
# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è Grid Search, –æ—Ü–µ–Ω–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.

# %%
# =================================================================
# –Ø—á–µ–π–∫–∞ 6: –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –æ—Ü–µ–Ω–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
# =================================================================

def grid_search_lgbm_classifier(
    X_train: np.ndarray, y_train: pd.Series,
    X_valid: np.ndarray, y_valid: pd.Series,
    base_params: dict,
    feature_names: list = None,
):
    param_grid = {
        "max_depth": [3, 5, 7], "learning_rate": [0.01, 0.03],
        "n_estimators": [200, 400], "colsample_bytree": [0.7, 0.9]
    }
    param_list = [dict(zip(param_grid.keys(), v)) for v in product(*param_grid.values())]
    best_logloss = float("inf")
    best_params, best_model = None, None

    for i, hp in enumerate(param_list, start=1):
        params = {**base_params, **hp}
        print(f"\n--- Grid Search: –ö–æ–º–±–∏–Ω–∞—Ü–∏—è {i}/{len(param_list)} ---")
        
        model = LGBMClassifier(**params)
        
        # Fit with early stopping and feature names
        model.fit(
            X_train, y_train,
            eval_set=[(X_valid, y_valid)],
            eval_metric="multi_logloss",
            callbacks=[early_stopping(30, verbose=False)],
            feature_name=feature_names if feature_names else 'auto'
        )

        y_pred_valid_proba = model.predict_proba(X_valid)
        # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –∫–ª–∞—Å—Å—ã –¥–ª—è log_loss
        loss = log_loss(y_valid, y_pred_valid_proba, labels=[0, 1, 2])
        print(f"Multi-LogLoss –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {loss:.5f}")

        if loss < best_logloss:
            best_logloss, best_params, best_model = loss, params, model
            print(">>> –ù–æ–≤—ã–π –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–¥–µ–ª—å.")

    print(f"\n=== –†–ï–ó–£–õ–¨–¢–ê–¢ GRID SEARCH ===\n–õ—É—á—à–∏–π LogLoss –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {best_logloss:.5f}\n–õ—É—á—à–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {best_params}")
    return {"best_model": best_model, "best_score": best_logloss, "best_params": best_params}

def evaluate_classifier(model: LGBMClassifier, X_test: np.ndarray, y_test: pd.Series) -> dict:
    y_pred = model.predict(X_test)
    print("\n" + "="*50 + "\n–û–¢–ß–ï–¢ –ü–û –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –ù–ê –¢–ï–°–¢–û–í–û–ô –í–´–ë–û–†–ö–ï\n" + "="*50)
    # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –∫–ª–∞—Å—Å—ã –¥–ª—è classification_report
    report = classification_report(y_test, y_pred, target_names=['DOWN (0)', 'SIDEWAYS (1)', 'UP (2)'], zero_division=0, labels=[0, 1, 2])
    print(report)
    print("="*50)
    
    cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2]) # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –∫–ª–∞—Å—Å—ã –¥–ª—è confusion_matrix
    plt.figure(figsize=(7, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Pred DOWN', 'Pred SIDEWAYS', 'Pred UP'], 
                yticklabels=['Actual DOWN', 'Actual SIDEWAYS', 'Actual UP'])
    plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫')
    plt.ylabel('–†–µ–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ')
    plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ')
    plt.show()
    
    return {"y_pred": y_pred}

def plot_advanced_signals(df: pd.DataFrame, test_indices: pd.Index, y_pred: Optional[np.ndarray] = None, y_true: Optional[pd.Series] = None):
    """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ë–ï–ó –†–ê–ó–†–´–í–û–í –≤ –ª–∏–Ω–∏–∏ —Ü–µ–Ω—ã."""
    fig, ax = plt.subplots(figsize=(16, 8))
    
    if test_indices.empty:
        print("–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø—É—Å—Ç–∞, –≥—Ä–∞—Ñ–∏–∫ –Ω–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω.")
        return
        
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å –≤ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
    last_day_in_test = test_indices.max().normalize()
    day_start_dt = last_day_in_test
    day_end_dt = last_day_in_test + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º test_indices –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–Ω—è
    test_indices_for_day = test_indices[(test_indices >= day_start_dt) & (test_indices <= day_end_dt)]

    if test_indices_for_day.empty:
        print(f"–ù–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–Ω—è {day_start_dt.strftime('%Y-%m-%d')}, –≥—Ä–∞—Ñ–∏–∫ –Ω–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω.")
        return

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ü–µ–Ω—ã –¥–ª—è —ç—Ç–æ–≥–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–Ω—è, –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã–µ –ø–æ test_indices_for_day
    plot_df_for_day = df.loc[test_indices_for_day].copy()

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–æ–π —Å–∏–≥–Ω–∞–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Ä–∞—Å–∫—Ä–∞—Å–∫–∏ —Ñ–æ–Ω–∞
    if y_pred is not None:
        full_signal_series = pd.Series(y_pred, index=test_indices)
        signals_for_day = full_signal_series.loc[test_indices_for_day]
        plot_title_prefix = "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (—Ñ–æ–Ω)"
    else:
        # –ï—Å–ª–∏ y_pred –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é 'y' –∏–∑ df_prepared
        signals_for_day = plot_df_for_day['y']
        plot_title_prefix = "–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (—Ñ–æ–Ω)"

    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ y_true –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Ä–∞—Å–∫—Ä–∞—Å–∫–∏ –ª–∏–Ω–∏–∏ —Ü–µ–Ω—ã
    if y_true is None:
        true_outcomes_for_day = plot_df_for_day['y'] # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Ü–µ–ª—å, –µ—Å–ª–∏ y_true –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω —è–≤–Ω–æ
    else:
        true_outcomes_for_day = y_true.loc[test_indices_for_day]


    print(f"–°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–Ω—è –≤ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {day_start_dt.strftime('%Y-%m-%d')}")
    print(f"–°–∏–≥–Ω–∞–ª—ã –¥–ª—è —Ñ–æ–Ω–∞ –∑–∞ {day_start_dt.strftime('%Y-%m-%d')}:\n{signals_for_day.value_counts()}")
    print(f"–†–µ–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã –∑–∞ {day_start_dt.strftime('%Y-%m-%d')}:\n{true_outcomes_for_day.value_counts()}")

    # 1. –†–∏—Å—É–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –ø–æ–ª–æ—Å—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (–∏–ª–∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π) - –±–æ–ª–µ–µ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–µ
    for i in range(len(signals_for_day)):
        idx = signals_for_day.index[i]
        end_idx = idx + pd.Timedelta(minutes=15)
        
        if signals_for_day.iloc[i] == 2: # UP
            ax.axvspan(idx, end_idx, color='lightgreen', alpha=0.15, lw=0)
        elif signals_for_day.iloc[i] == 0: # DOWN
            ax.axvspan(idx, end_idx, color='lightcoral', alpha=0.15, lw=0)
        else: # SIDEWAYS
            ax.axvspan(idx, end_idx, color='lightgray', alpha=0.15, lw=0)

    # 2. –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –†–∏—Å—É–µ–º –ù–ï–ü–†–ï–†–´–í–ù–£–Æ –ª–∏–Ω–∏—é —Ü–µ–Ω—ã –ë–ï–ó —Ä–∞–∑—Ä—ã–≤–æ–≤!
    price_data = plot_df_for_day['close']
    ax.plot(price_data.index, price_data.values, color='black', linewidth=2, label='–¶–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è', alpha=0.8, zorder=3)

    # 3. –î–æ–±–∞–≤–ª—è–µ–º —Ü–≤–µ—Ç–Ω—ã–µ —Ç–æ—á–∫–∏ –ø–æ–≤–µ—Ä—Ö –ª–∏–Ω–∏–∏ –¥–ª—è –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
    for class_val, color, label in [(0, 'red', 'DOWN'), (1, 'gray', 'SIDEWAYS'), (2, 'green', 'UP')]:
        mask = true_outcomes_for_day == class_val
        if mask.any():
            class_prices = price_data[mask]
            class_times = true_outcomes_for_day[mask].index
            ax.scatter(class_times, class_prices, color=color, s=40, alpha=0.9,
                      label=f'–†–µ–∞–ª—å–Ω—ã–π {label}', zorder=5, edgecolors='white', linewidth=0.5)

    # –û–ì–†–ê–ù–ò–ß–ò–í–ê–ï–ú –ú–ê–°–®–¢–ê–ë –¢–û–õ–¨–ö–û –ü–û –¶–ï–ù–ï (—á—Ç–æ–±—ã FFT –Ω–µ –ª–æ–º–∞–ª –º–∞—Å—à—Ç–∞–±)
    price_min = price_data.min()
    price_max = price_data.max()
    price_range = price_max - price_min
    margin = price_range * 0.1  # 10% –æ—Ç—Å—Ç—É–ø—ã
    
    ax.set_ylim(price_min - margin, price_max + margin)
    
    # –û–ë–†–ï–ó–ê–ï–ú FFT –°–ò–ì–ù–ê–õ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É —Ü–µ–Ω—ã (—á—Ç–æ–±—ã –æ–Ω –Ω–µ –≤—ã—Ö–æ–¥–∏–ª –∑–∞ –ø—Ä–µ–¥–µ–ª—ã)
    if 'fft_signal' in plot_df_for_day.columns and not plot_df_for_day['fft_signal'].isnull().all():
        fft_signal = plot_df_for_day['fft_signal'].copy()
        # –û–±—Ä–µ–∑–∞–µ–º FFT —Å–∏–≥–Ω–∞–ª –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É —Ü–µ–Ω—ã
        fft_signal_masked = fft_signal.copy()
        fft_signal_masked[fft_signal_masked < price_min - margin] = np.nan
        fft_signal_masked[fft_signal_masked > price_max + margin] = np.nan
        
        ax.plot(plot_df_for_day.index, fft_signal_masked, color='blue', linestyle='--', label='FFT Signal', alpha=0.7, zorder=4)

    ax.set_title(f"{plot_title_prefix} vs –†–µ–∞–ª—å–Ω–æ—Å—Ç—å (—Ç–æ—á–∫–∏) –∑–∞ {day_start_dt.strftime('%Y-%m-%d')}")
    ax.set_xlabel("–í—Ä–µ–º—è")
    ax.set_ylabel("–¶–µ–Ω–∞")
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    ax.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

def plot_fft_comparison(df: pd.DataFrame, start_idx: int = 0, end_idx: int = 500):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã –∏ FFT —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏."""
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
    end_idx = min(end_idx, len(df))
    
    # –ì—Ä–∞—Ñ–∏–∫ 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã –∏ FFT —Å–∏–≥–Ω–∞–ª–∞
    ax1.plot(range(start_idx, end_idx), df['close'].iloc[start_idx:end_idx],
             label='–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞', color='blue', alpha=0.7)
    ax1.plot(range(start_idx, end_idx), df['fft_signal'].iloc[start_idx:end_idx],
             label='FFT —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è', color='red', linestyle='--', linewidth=2)
    ax1.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ vs FFT —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è')
    ax1.set_xlabel('–ò–Ω–¥–µ–∫—Å –≤—Ä–µ–º–µ–Ω–∏')
    ax1.set_ylabel('–¶–µ–Ω–∞')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ 2: FFT —Å–∏–≥–Ω–∞–ª –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª
    ax2.plot(range(start_idx, end_idx), df['fft_signal_diff'].iloc[start_idx:end_idx],
             label='FFT —Å–∏–≥–Ω–∞–ª (–¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª)', color='green', linewidth=1.5)
    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    ax2.axhline(y=0.003, color='red', linestyle='--', alpha=0.5, label='Threshold +')
    ax2.axhline(y=-0.003, color='red', linestyle='--', alpha=0.5, label='Threshold -')
    ax2.set_title('FFT —Å–∏–≥–Ω–∞–ª –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ü–µ–ª–∏')
    ax2.set_xlabel('–ò–Ω–¥–µ–∫—Å –≤—Ä–µ–º–µ–Ω–∏')
    ax2.set_ylabel('–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ FFT:")
    print(f"- –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º –∏ FFT: {np.corrcoef(df['close'].iloc[start_idx:end_idx], df['fft_signal'].iloc[start_idx:end_idx])[0,1]:.4f}")
    print(f"- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ FFT: {np.std(df['fft_signal'].iloc[start_idx:end_idx]):.6f}")
    print(f"- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ FFT –¥–∏—Ñ—Ñ: {np.std(df['fft_signal_diff'].iloc[start_idx:end_idx]):.6f}")

def add_multiple_fft_targets(df: pd.DataFrame, cutoff_ratios: list, thresholds: list, fft_components: int = 10) -> pd.DataFrame:
    """–°–æ–∑–¥–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ FFT —Ü–µ–ª–µ–π —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""
    df_result = df.copy()
    
    for i, cutoff_ratio in enumerate(cutoff_ratios):
        for j, threshold in enumerate(thresholds):
            # –£–±–∏—Ä–∞–µ–º —Ç—Ä–µ–Ω–¥ –¥–ª—è –ª—É—á—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ FFT
            close_prices = df_result['close'].values
            mean_price = np.mean(close_prices)
            detrended_prices = close_prices - mean_price
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º FFT –∫ –¥–µ—Ç—Ä–µ–Ω–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–µ—Ä–∏–∏
            yf = fft(detrended_prices)
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω—ã—Ö —à—É–º–æ–≤
            yf_filtered = np.zeros_like(yf, dtype=complex)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—É —á–∞—Å—Ç–æ—Ç –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            cutoff_freq = int(len(close_prices) * cutoff_ratio)
            
            # –û—Å—Ç–∞–≤–ª—è–µ–º –Ω–∏–∑–∫–æ—á–∞—Å—Ç–æ—Ç–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–≤–∫–ª—é—á–∞—è DC)
            yf_filtered[:cutoff_freq] = yf[:cutoff_freq]
            if len(close_prices) % 2 == 0:  # –ï—Å–ª–∏ N —á–µ—Ç–Ω–æ–µ
                yf_filtered[len(close_prices)-cutoff_freq:] = yf[len(close_prices)-cutoff_freq:]
            else:  # –ï—Å–ª–∏ N –Ω–µ—á–µ—Ç–Ω–æ–µ
                yf_filtered[len(close_prices)-cutoff_freq+1:] = yf[len(close_prices)-cutoff_freq+1:]
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ–µ FFT –¥–ª—è —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞
            fft_reconstructed_detrended = ifft(yf_filtered).real
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç—Ä–µ–Ω–¥
            fft_reconstructed_signal = fft_reconstructed_detrended + mean_price
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º FFT —Å–∏–≥–Ω–∞–ª
            col_name = f'fft_signal_cutoff_{cutoff_ratio}_thresh_{threshold}'
            df_result[col_name] = fft_reconstructed_signal
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É FFT —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–∏
            fft_log_returns = np.diff(np.log(fft_reconstructed_signal[fft_reconstructed_signal > 0]))
            fft_signal_diff = np.concatenate([[0], fft_log_returns])
            diff_col_name = f'fft_signal_diff_cutoff_{cutoff_ratio}_thresh_{threshold}'
            df_result[diff_col_name] = fft_signal_diff
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ fft_signal_diff —Å —É—á–µ—Ç–æ–º –∫–æ–º–∏—Å—Å–∏–∏
            min_signal = 7 * COMMISSION
            effective_threshold = max(threshold, min_signal)
            
            conditions = [df_result[diff_col_name] > effective_threshold, df_result[diff_col_name] < -effective_threshold]
            choices = [2, 0] # 2 –¥–ª—è UP, 0 –¥–ª—è DOWN
            target_col_name = f'y_fft_cutoff_{cutoff_ratio}_thresh_{threshold}'
            df_result[target_col_name] = np.select(conditions, choices, default=1) # 1 –¥–ª—è SIDEWAYS
            
            print(f"FFT –í–∞—Ä–∏–∞–Ω—Ç {i*len(thresholds)+j+1}: cutoff_ratio={cutoff_ratio}, threshold={effective_threshold:.6f} (base: {threshold}, min: {min_signal:.6f})")
            print(f"  - –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º: {np.corrcoef(close_prices, fft_reconstructed_signal)[0,1]:.4f}")
            print(f"  - –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {df_result[target_col_name].value_counts().to_dict()}")
            print()
    
    return df_result

def plot_multiple_fft_comparison(df: pd.DataFrame, start_idx: int = 0, end_idx: int = 500):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ FFT —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏."""
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ FFT –∫–æ–ª–æ–Ω–∫–∏
    fft_signal_cols = [col for col in df.columns if col.startswith('fft_signal_cutoff_') and not 'diff' in col]
    
    if not fft_signal_cols:
        print("–ù–µ –Ω–∞–π–¥–µ–Ω–æ FFT –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
        return
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
    end_idx = min(end_idx, len(df))
    
    # –°–æ–∑–¥–∞–µ–º subplot –¥–ª—è –∫–∞–∂–¥–æ–≥–æ FFT –≤–∞—Ä–∏–∞–Ω—Ç–∞
    n_plots = len(fft_signal_cols) + 1  # +1 –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã
    n_cols = 2
    n_rows = (n_plots + 1) // 2
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 6*n_rows))
    if n_rows == 1:
        axes = axes.reshape(1, -1)
    
    # –ü–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ –æ—Å–µ–π
    axes_flat = axes.flatten()
    
    # –ì—Ä–∞—Ñ–∏–∫ 1: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞
    axes_flat[0].plot(range(start_idx, end_idx), df['close'].iloc[start_idx:end_idx],
                     label='–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞', color='blue', linewidth=2)
    axes_flat[0].set_title('–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞')
    axes_flat[0].set_xlabel('–ò–Ω–¥–µ–∫—Å –≤—Ä–µ–º–µ–Ω–∏')
    axes_flat[0].set_ylabel('–¶–µ–Ω–∞')
    axes_flat[0].legend()
    axes_flat[0].grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ FFT –≤–∞—Ä–∏–∞–Ω—Ç–∞
    for i, fft_col in enumerate(fft_signal_cols):
        if i + 1 < len(axes_flat):
            axes_flat[i + 1].plot(range(start_idx, end_idx), df['close'].iloc[start_idx:end_idx],
                                 label='–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è', color='blue', alpha=0.5, linewidth=1)
            axes_flat[i + 1].plot(range(start_idx, end_idx), df[fft_col].iloc[start_idx:end_idx],
                                 label='FFT', color='red', linewidth=2, linestyle='--')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–∫–∏
            params = fft_col.replace('fft_signal_cutoff_', '').split('_thresh_')
            cutoff_ratio = params[0]
            threshold = params[1]
            
            axes_flat[i + 1].set_title(f'FFT: cutoff={cutoff_ratio}, threshold={threshold}')
            axes_flat[i + 1].set_xlabel('–ò–Ω–¥–µ–∫—Å –≤—Ä–µ–º–µ–Ω–∏')
            axes_flat[i + 1].set_ylabel('–¶–µ–Ω–∞')
            axes_flat[i + 1].legend()
            axes_flat[i + 1].grid(True, alpha=0.3)
    
    # –°–∫—Ä—ã–≤–∞–µ–º –ª–∏—à–Ω–∏–µ subplots
    for i in range(len(fft_signal_cols) + 1, len(axes_flat)):
        axes_flat[i].axis('off')
    
    plt.tight_layout()
    plt.show()

def plot_feature_importance(model, feature_names):
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    plt.figure(figsize=(10, 10))
    plt.barh(importance_df['feature'], importance_df['importance'])
    plt.title('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.show()

def auto_optimize_fft_parameters(
    df_featured: pd.DataFrame,
    cutoff_ratios: list,
    thresholds: list,
    target_col: str = "y"
) -> dict:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è FFT –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –ø–æ–∏—Å–∫–æ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏."""
    
    results = {}
    best_return = float('-inf')
    best_params = None
    best_model = None
    best_data = None
    
    print("üîç –ù–ê–ß–ò–ù–ê–ï–ú –ê–í–¢–û–û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Æ FFT –ü–ê–†–ê–ú–ï–¢–†–û–í...")
    print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print(f"- Cutoff ratios: {cutoff_ratios}")
    print(f"- Thresholds: {thresholds}")
    print(f"- –í—Å–µ–≥–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π: {len(cutoff_ratios) * len(thresholds)}")
    print("=" * 60)
    
    for i, cutoff_ratio in enumerate(cutoff_ratios):
        for j, threshold in enumerate(thresholds):
            combo_num = i * len(thresholds) + j + 1
            total_combos = len(cutoff_ratios) * len(thresholds)
            
            print(f"\nüîÑ –ö–æ–º–±–∏–Ω–∞—Ü–∏—è {combo_num}/{total_combos}")
            print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: cutoff_ratio={cutoff_ratio}, threshold={threshold:.6f}")
            print("-" * 40)
            
            try:
                # 1. –°–æ–∑–¥–∞–µ–º —Ü–µ–ª—å —Å —Ç–µ–∫—É—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                df_targeted = add_target(
                    df_featured,
                    threshold=threshold,
                    cutoff_ratio=cutoff_ratio
                )
                
                # üö® –ü–†–û–í–ï–†–ö–ê: –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ (>95%), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                neutral_ratio = (df_targeted['y'] == 1).mean()
                # if neutral_ratio > 0.9999:
                #     print(f"‚è≠Ô∏è  –ü–†–û–ü–£–°–ö: –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ ({neutral_ratio:.2%} > 95%)")
                #     results[f"cutoff_{cutoff_ratio}_thresh_{threshold:.6f}"] = {
                #         'cutoff_ratio': cutoff_ratio,
                #         'threshold': threshold,
                #         'logloss': np.nan,
                #         'total_return': -999,  # –û—á–µ–Ω—å –ø–ª–æ—Ö–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                #         'sharpe': -999,
                #         'max_drawdown': -999,
                #         'win_rate': -999,
                #         'model': None,
                #         'skipped': True,
                #         'reason': f'–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤: {neutral_ratio:.2%} > 95%'
                #     }
                #     continue
                
                print(f"üìä –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤: {neutral_ratio:.2%} (–û–ö)")
                
                # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                (
                    X_train_scaled, y_train,
                    X_valid_scaled, y_valid,
                    X_test_scaled, y_test,
                    scaler, feature_columns, test_indices, df_prepared
                ) = prepare_features_and_split(
                    df=df_targeted, target_col=target_col, train_ratio=0.7, valid_ratio=0.15,
                )
                
                # 3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                base_params = {
                    'objective': 'multiclass',
                    'num_class': 3,
                    'metric': 'multi_logloss',
                    'random_state': RANDOM_STATE,
                    'verbose': -1,
                    'device': 'gpu' if USE_GPU else 'cpu'
                }
                
                grid_result = grid_search_lgbm_classifier(
                    X_train=X_train_scaled, y_train=y_train,
                    X_valid=X_valid_scaled, y_valid=y_valid,
                    base_params=base_params,
                    feature_names=feature_columns
                )
                
                model = grid_result["best_model"]
                logloss = grid_result["best_score"]
                
                # 4. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                y_pred = model.predict(X_test_scaled)
                
                # 5. –ê–≤—Ç–æ–±—ç–∫—Ç–µ—Å—Ç
                backtest_stats = advanced_backtester(
                    df=df_prepared,
                    predictions=y_pred,
                    test_indices=test_indices,
                    model_name=f"FFT_opt_{cutoff_ratio}_{threshold:.6f}",
                    risk_free_rate=0.05,
                    save_plot=False  # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
                )
                
                # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                total_return = backtest_stats.get('total_return', 0)
                
                results[f"cutoff_{cutoff_ratio}_thresh_{threshold:.6f}"] = {
                    'cutoff_ratio': cutoff_ratio,
                    'threshold': threshold,
                    'logloss': logloss,
                    'total_return': total_return,
                    'sharpe': backtest_stats.get('sharpe_ratio', 0),
                    'max_drawdown': backtest_stats.get('max_drawdown', 0),
                    'win_rate': backtest_stats.get('win_rate', 0),
                    'neutral_ratio': neutral_ratio,
                    'model': model,
                    'data': {
                        'df_prepared': df_prepared,
                        'test_indices': test_indices,
                        'predictions': y_pred,
                        'y_test': y_test
                    }
                }
                
                print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: Return={total_return:.4f}, Sharpe={backtest_stats.get('sharpe_ratio', 0):.4f}")
                
                # 7. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if total_return > best_return:
                    best_return = total_return
                    best_params = (cutoff_ratio, threshold)
                    best_model = model
                    best_data = {
                        'df_prepared': df_prepared,
                        'test_indices': test_indices,
                        'predictions': y_pred,
                        'y_test': y_test
                    }
                    print(f"üèÜ –ù–û–í–´–ô –õ–£–ß–®–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢! Return={best_return:.4f}")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {e}")
                continue
    
    # 8. –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "="*60)
    print("üèÅ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–í–¢–û–û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
    print("="*60)
    
    # –ü–æ–¥—Å—á–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
    skipped_count = sum(1 for r in results.values() if r.get('skipped', False))
    total_count = len(results)
    successful_count = total_count - skipped_count
    
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–û–¶–ï–°–°–ê:")
    print(f"   –í—Å–µ–≥–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π: {total_count}")
    print(f"   –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {successful_count}")
    print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ (—Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –Ω–µ–π—Ç—Ä–∞–ª–æ–≤): {skipped_count}")
    print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—Å–∫–∞: {skipped_count/total_count:.1%}")
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
    successful_results = {k: v for k, v in results.items() if not v.get('skipped', False)}
    
    if successful_results:
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ —Ç–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        sorted_results = sorted(successful_results.items(), key=lambda x: x[1]['total_return'], reverse=True)
        
        print("\nüèÜ –¢–û–ü-5 –õ–£–ß–®–ò–• –ö–û–ú–ë–ò–ù–ê–¶–ò–ô:")
        for i, (name, stats) in enumerate(sorted_results[:5], 1):
            print(f"{i}. {name}")
            print(f"   Return: {stats['total_return']:.4f} | Sharpe: {stats['sharpe']:.4f} | LogLoss: {stats['logloss']:.5f}")
            print(f"   –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö: {stats['neutral_ratio']:.2%}")
        
        print(f"\nü•á –õ–£–ß–®–ò–ï –ü–ê–†–ê–ú–ï–¢–†–´:")
        print(f"   Cutoff ratio: {best_params[0]}")
        print(f"   Threshold: {best_params[1]:.6f}")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {best_return:.4f}")
    else:
        print("\n‚ùå –ù–ò –û–î–ù–û–ô –ö–û–ú–ë–ò–ù–ê–¶–ò–ò –ù–ï –ü–†–û–®–õ–ê –ü–†–û–í–ï–†–ö–£ –ù–ê –ù–ï–ô–¢–†–ê–õ–¨–ù–´–ï –°–ò–ì–ù–ê–õ–´!")
        print("üîß –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –£–≤–µ–ª–∏—á–∏—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω threshold –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å cutoff_ratios")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
    if skipped_count > 0:
        print(f"\n‚è≠Ô∏è –ü–†–ò–ú–ï–†–´ –ü–†–û–ü–£–©–ï–ù–ù–´–• –ö–û–ú–ë–ò–ù–ê–¶–ò–ô:")
        skipped_examples = [(k, v) for k, v in results.items() if v.get('skipped', False)][:3]
        for name, stats in skipped_examples:
            print(f"   ‚ùå {name}: {stats.get('reason', 'Unknown reason')}")
    
    return {
        'best_params': best_params,
        'best_model': best_model,
        'best_data': best_data,
        'best_return': best_return,
        'all_results': results,
        'sorted_results': sorted_results if successful_results else []
    }

# %% [markdown]
# ## –®–∞–≥ 6: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è FFT –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
#
# –ó–∞–ø—É—Å–∫–∞–µ–º —Ü–∏–∫–ª –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ FFT —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å—é.

# %%
# =============================================
# –Ø—á–µ–π–∫–∞ 7: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
# =============================================
def __main__():
    print("üöÄ –ó–ê–ü–£–°–ö –ê–í–¢–û–û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò FFT –ü–ê–†–ê–ú–ï–¢–†–û–í...")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–¥–∏–Ω —Ä–∞–∑
    df_raw = load_and_merge_data()
    df_featured = add_volume_features(df_raw)
    df_featured = add_strategy_features(df_featured)
    df_featured = add_volatility_features(df_featured)

    # –î–∏–∞–ø–∞–∑–æ–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    cutoff_ratios = [0.005, 0.01, 0.02, 0.05, 0.1, 0.15]  # 0.5%-15% —á–∞—Å—Ç–æ—Ç
    thresholds = [
        0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.003, 0.005, 0.008
    ]  # –†–∞–∑–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
    optimization_results = auto_optimize_fft_parameters(
        df_featured=df_featured,
        cutoff_ratios=cutoff_ratios,
        thresholds=thresholds
    )

    print("\nüéâ –ê–í–¢–û–û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
    print("="*50)

    # –ò—Ç–æ–≥–æ–≤–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    if optimization_results['best_model'] is not None:
        print("\nüìà –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")

        best_data = optimization_results['best_data']
        plot_advanced_signals(
            df=best_data['df_prepared'],
            test_indices=best_data['test_indices'],
            y_pred=best_data['predictions'],
            y_true=best_data['y_test']
        )

        # –§–∏–Ω–∞–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≥—Ä–∞—Ñ–∏–∫–∞
        print("\nüîç –§–∏–Ω–∞–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≥—Ä–∞—Ñ–∏–∫–∞...")
        final_backtest_stats = advanced_backtester(
            df=best_data['df_prepared'],
            predictions=best_data['predictions'],
            test_indices=best_data['test_indices'],
            model_name="FINAL_OPTIMIZED",
            risk_free_rate=0.05,
            save_plot=True,
            plot_filename="optimized_fft_lgbm_backtest.png"
        )

        print(f"\nüìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò:")
        print(f"   üéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: cutoff_ratio={optimization_results['best_params'][0]}, threshold={optimization_results['best_params'][1]:.6f}")
        print(f"   üí∞ –ò—Ç–æ–≥–æ–≤–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {optimization_results['best_return']:.4f}")
        print(f"   üìà Sharpe Ratio: {final_backtest_stats.get('sharpe_ratio', 0):.4f}")
        print(f"   üìâ Max Drawdown: {final_backtest_stats.get('max_drawdown', 0):.4f}")
        print(f"   ‚úÖ Win Rate: {final_backtest_stats.get('win_rate', 0):.4f}")
        print(f"   üìÅ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: optimized_fft_lgbm_backtest.png")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")



if __name__ == "__main__":
    __main__()

#